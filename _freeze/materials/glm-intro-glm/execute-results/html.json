{
  "hash": "083978e3228e9f834446b5fc0ef9d2a4",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Generalising your model\"\n---\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n## Putting the \"G\" into GLM\n\nIn the previous linear model example all the assumptions were met. But what if we have data where that isn't the case? For example, what if we have data where we _can't_ describe the relationship between the predictor and response variables in a linear way?\n\nOne of the ways we can deal with this is by using a **generalised linear model**, also abbreviated as GLM. In a way it's an extension of the linear model we discussed in the previous section. As with the normal linear model, the predictor variables in the model are in a linear combination, such as:\n\n$$\n\\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\beta_3X_3 + ...\n$$\n\nHere, the $\\beta_0$ value is the constant or intercept, whereas each subsequent $\\beta_i$ is a unique regression coefficient for each $X_i$ predictor variable. So far so good.\n\nHowever, the GLM makes the linear model more flexible in two ways:\n\n:::{.callout-important}\n1. In a standard linear model the linear combination (e.g. like we see above) becomes the predicted outcome value. With a GLM a transformation is specified, which turns the linear combination into the predicted outcome value. This is called a **link function**.\n2. A standard linear model assumes a continuous, normally distributed outcome, whereas **with GLM the outcome can be both continuous or integer**. Furthermore, the outcome does not have to be normally distributed. Indeed, **the outcome can follow a different kind of distribution**, such as binomial, Poisson, exponential etc.\n:::\n\nWe'll introduce each of these elements below, then illustrate how they are used in practice, using different types of data.\n\nThe link function and different distributions are closely...err, _linked_. To make sense of what the link function is doing it's useful to understand the different distributional assumptions. So we'll start with those.\n\n## Distributions\n\nIn the examples of a standard linear model we've seen that the residuals needed to be normally distributed. We've mainly used the Q-Q plot to assess this assumption of normality.\n\nBut what does \"normal\" actually mean? It assumes that the residuals are coming from a normal or Gaussian distribution. This distribution has a symmetrical bell-shape, where the centre is the mean, and half of the data are on either side of this.\n\nWe can see this in @fig-normdist. The mean of the normal distribution is indicated with the dashed blue line.\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![Normal distribution](glm-intro-glm_files/figure-html/fig-normdist-1.png){#fig-normdist width=672}\n:::\n:::\n\n\nWe can use the linear model we created previously, where we looked at the possible linear relationship between beak depth and beak length. This is based on measurements of _G. fortis_ beaks in 1975.\n\nThe individual values of the residuals from this linear model are shown in @fig-normdist, panel B (in red), with the corresponding theoretical normal distribution in the background. We can see that the residuals follow this distribution reasonably well, which matches our conclusions from the Q-Q plot (see @fig-fortis1975_lm_dgplots).\n\nAll this means is that assuming that these residuals may come from a normal distribution isn't such a daft suggestion after all.\n\nNow look at the example in @fig-beak_shape. This shows the classification of beak shape for a number of finches. Their beaks are either classed as `blunt` or `pointed`. Various (continuous) measurements were taken from each bird, with the beak length shown here.\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![Classification in beak shape](glm-intro-glm_files/figure-html/fig-beak_shape-1.png){#fig-beak_shape width=672}\n:::\n:::\n\n\nWe'll look into this example in more detail later. For now it's important to note that the response variable (the beak shape classification) is not continuous. Here it is a binary response (`blunt` or `pointed`). As a result, the assumptions for a regular linear model go out of the window. If we were foolish enough to fit a linear model to these data (see blue line in A), then the residuals would look rather non-normal (@fig-beak_shape B).\n\nSo what do we do? Well, the normal distribution is not the only one there is. In @fig-dist_examples there are a few examples of distributions (including the normal one).\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Different distributions](glm-intro-glm_files/figure-html/fig-dist_examples-1.png){#fig-dist_examples width=672}\n:::\n:::\n\n\nDifferent distributions are useful for different types of data. For example, a logistic distribution is particularly useful in the context of binary or proportional response data. The Poisson distribution is useful when we have count data as a response.\n\nIn order to understand how this can help us, we need to be aware of two more concepts: **linear predictors** and **link functions**.\n\n## Linear predictors\n\nThe nice thing about linear models is that the predictors are, well, linear. Straight lines make for easy interpretation of any potential relationship between predictor and response.\n\nAs mentioned before, predictors are in the form of a _linear combination_, where each predictor variable is multiplied by a coefficient and all the terms are added together:\n\n$$\n\\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\beta_3X_3 + ...\n$$\n\nFortunately, this is no different for generalised linear models! We still have a linear combination but, as we'll see, if the relationship is not linear then we need an additional step before we can model the data in this way.\n\nAt this point, we have two options at our disposal (well, there are more, but let's not muddy the waters too much).\n\n:::{.callout-important}\n\n1. Transform our data and use a normal linear model on the transformed data\n2. Transform the linear predictor\n:::\n\nThe first option, to **transform our data**, seems like a useful option and can work. It keeps things familiar (we'd still use a standard linear model) and so all is well with the world. Up to the point of interpreting the data. If we, for example, log-transform our data, how do we interpret this? After all, the predictions of the linear model are directly related to the outcome or response variable. Transforming the data is usually done so that the residuals of the linear model resemble a more normal distribution. An unwanted side-effect of this is that this also changes the ratio scale properties of the measured variables [@stevens1946].\n\nThe second option would be to **transform the linear predictor**. This enables us to map a *non-linear* outcome (or response variable) to a *linear* model. This transformation is done using a **link function**.\n\n## Link functions\n\nSimply put: link functions connect the predictors in our model to the response variables in a linear way. \n\nHowever, and similar to the standard linear model, there are two parts to each model:\n\n1. the coefficients for each predictor (linking each parameter to a predictor)\n2. the error or random component (which specifies a probability distribution)\n\nWhich link function you use depends on your analysis. Some common link functions and corresponding distributions are (adapted from [@glen2021]):\n\n| distribution | data type           | link name |\n|--------------|---------------------|-----------|\n| binomial     | binary / proportion | logit     |\n| normal       | any real number     | identity  |\n| poisson      | count data          | log       |\n\n\nLet's again look at the earlier example of beak shape.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Beak shape classification](glm-intro-glm_files/figure-html/fig-beak_shapeclass-1.png){#fig-beak_shapeclass width=672}\n:::\n:::\n\n\nWe've seen the data in @fig-beak_shapeclass A before, where we had information on what beak shape our observed finches had, plotted against their beak length.\n\nLet's say we now want to make some **predictions** about what beak shape we would expect, *given* a certain beak length. In this scenario we'd need some way of modelling the response variable (beak shape; `blunt` or `pointed`) as a function of the predictor variable (beak length).\n\nThe issue we have is that the response variable is not continuous, but binary! We could fit a standard linear model to these data (blue line in @fig-beak_shape A) but this is really bad practice. Why? Well, what such a linear model represents is *the probability* - or how likely it is - that an observed finch has a pointed beak, given a certain beak length (@fig-beak_shapeclass B).\n\nSimply fitting a linear line through those data suggests that it is possible to have a higher than 1 and lower-than-zero probability that a beak would be pointed! That, of course, makes no sense. So, we can't describe these data as a linear relationship.\n\nInstead, we'll use a *logistic model* to analyse these data. We'll cover the practicalities of how to do this in more detail in a later chapter, but for now it's sufficient to realise that one of the ways we could model these data could look like this:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Logistic model for beak classification](glm-intro-glm_files/figure-html/fig-beak_shape_glm-1.png){#fig-beak_shape_glm width=672}\n:::\n:::\n\n\nUsing this sigmoidal curve ensures that our predicted probabilities do not exceed the $[0, 1]$ range.\n\nNow, what happened behind the scenes is that the generalised linear model has taken the linear predictor and transformed it using the *logit* link function. This links the  non-linear response variable (beak shape) to a linear model, using beak length as a predictor.\n\nWe'll practice how to perform this analysis in the next section.\n\n## Summary\n\n::: {.callout-tip}\n#### Key points\n\n- GLMs allow us to map a non-linear outcome to a linear model\n- The link function determines *how* this occurs, transforming the linear predictor\n:::\n",
    "supporting": [
      "glm-intro-glm_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}